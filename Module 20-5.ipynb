{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "hp_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS and Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [   58.64977899 20526.59671243 15617.48454101 -8280.94448954\n",
      " 11563.95865355   344.45117267   298.66280008  -910.88281567]\n",
      "\n",
      "Intercept: \n",
      " -1320759.3485210259\n"
     ]
    }
   ],
   "source": [
    "# Y is the target variable\n",
    "Y = hp_df['saleprice']\n",
    "# X is the feature set\n",
    "X = hp_df[['grlivarea','overallqual', 'garagecars', 'fullbath', 'fireplaces', 'yearbuilt', 'yearremodadd', 'totrmsabvgrd']]\n",
    "\n",
    "# We create a LinearRegression model object\n",
    "# from scikit-learn's linear_model module.\n",
    "lrm = linear_model.LinearRegression()\n",
    "\n",
    "# fit method estimates the coefficients using OLS\n",
    "lrm.fit(X, Y)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nCoefficients: \\n', lrm.coef_)\n",
    "print('\\nIntercept: \\n', lrm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in training set is 1168\n",
      "The number of observations in test set is 292\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of observations in training set is {}\".format(X_train.shape[0]))\n",
    "print(\"The number of observations in test set is {}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              saleprice   R-squared:                       0.762\n",
      "Model:                            OLS   Adj. R-squared:                  0.760\n",
      "Method:                 Least Squares   F-statistic:                     463.5\n",
      "Date:                Mon, 24 Jun 2019   Prob (F-statistic):               0.00\n",
      "Time:                        11:30:04   Log-Likelihood:                -13988.\n",
      "No. Observations:                1168   AIC:                         2.799e+04\n",
      "Df Residuals:                    1159   BIC:                         2.804e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const         -1.26e+06   1.48e+05     -8.532      0.000   -1.55e+06    -9.7e+05\n",
      "grlivarea       48.3220      4.751     10.172      0.000      39.001      57.643\n",
      "overallqual   2.129e+04   1361.231     15.643      0.000    1.86e+04     2.4e+04\n",
      "garagecars    1.631e+04   2072.484      7.869      0.000    1.22e+04    2.04e+04\n",
      "fullbath     -6460.8656   3019.558     -2.140      0.033   -1.24e+04    -536.453\n",
      "fireplaces    1.245e+04   2018.435      6.171      0.000    8494.757    1.64e+04\n",
      "yearbuilt      332.9103     56.486      5.894      0.000     222.084     443.736\n",
      "yearremodadd   274.3124     72.697      3.773      0.000     131.679     416.946\n",
      "totrmsabvgrd  1563.8492   1293.749      1.209      0.227    -974.503    4102.202\n",
      "==============================================================================\n",
      "Omnibus:                      324.478   Durbin-Watson:                   1.914\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13075.422\n",
      "Skew:                           0.523   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.358   Cond. No.                     4.18e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.18e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# We fit an OLS model using statsmodels\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# We print the summary results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsRegressor(n_neighbors=15)\n",
    "X = X_train\n",
    "Y = y_train\n",
    "knn.fit(X, Y)\n",
    "\n",
    "# Set up our prediction line.\n",
    "T = X_test\n",
    "\n",
    "# Trailing underscores are a common convention for a prediction.\n",
    "Y_ = knn.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: 0.63 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(knn, X, Y, cv=5)\n",
    "print(\"Unweighted Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS model seems to be superior, with an R^2 value of 0.76, compared to 0.63 for the KNN regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
